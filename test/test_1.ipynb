{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/venv_3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/homebrew/anaconda3/envs/venv_3.11/lib/python3.11/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/anaconda3/envs/venv_3.11/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <EB3FF92A-5EB1-3EE8-AF8B-5923C1265422> /opt/homebrew/anaconda3/envs/venv_3.11/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/opt/homebrew/anaconda3/envs/venv_3.11/lib/python3.11/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/homebrew/anaconda3/envs/venv_3.11/lib/python3.11/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/homebrew/anaconda3/envs/venv_3.11/lib/python3.11/lib-dynload/../../libjpeg.9.dylib' (no such file), '/opt/homebrew/anaconda3/envs/venv_3.11/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/opt/homebrew/anaconda3/envs/venv_3.11/lib/python3.11/site-packages/hyperopt/atpe.py:19: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "# Library\n",
    "# Time\n",
    "from timeit import default_timer as timer\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# File\n",
    "import warnings\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import random\n",
    "import chardet\n",
    "import itertools\n",
    "\n",
    "# Numerical & Data Handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import math\n",
    "from typing import List, Callable, Union, Dict, Any, Tuple\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "%matplotlib inline\n",
    "from sklearn.tree import plot_tree\n",
    "from scipy.optimize import curve_fit\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import mpl_toolkits.axisartist as AA\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, ParameterGrid\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "from sklearn.ensemble import (RandomForestClassifier, RandomForestRegressor, \n",
    "\t\t\t\t\t\t\t  ExtraTreesClassifier, ExtraTreesRegressor, \n",
    "\t\t\t\t\t\t\t  BaggingClassifier, BaggingRegressor, \n",
    "\t\t\t\t\t\t\t  GradientBoostingClassifier, GradientBoostingRegressor, \n",
    "\t\t\t\t\t\t\t  AdaBoostClassifier, AdaBoostRegressor, \n",
    "\t\t\t\t\t\t\t  VotingClassifier, VotingRegressor,\n",
    "\t\t\t\t\t\t\t  StackingClassifier, StackingRegressor)\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, ElasticNet, Lasso, Ridge\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "# Neural Network Libraries\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms import ToTensor\n",
    "import huggingface\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from transformers import pipeline\n",
    "\n",
    "# Feature Engineering\n",
    "from sklearn.preprocessing import (StandardScaler, RobustScaler, MinMaxScaler, MaxAbsScaler, Normalizer, \n",
    "\t\t\t\t\t\t\t\t   LabelEncoder, OneHotEncoder, OrdinalEncoder, LabelBinarizer)\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif, RFE, SequentialFeatureSelector, VarianceThreshold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.impute import SimpleImputer\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from hyperopt import hp, tpe, fmin, Trials\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Dimensionality Reduction\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Time-Series Analysis\n",
    "from statsmodels.tsa.seasonal import STL, seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import (classification_report, pairwise_distances, silhouette_score, \n",
    "\t\t\t\t\t\t\t roc_curve, auc, roc_auc_score, RocCurveDisplay, \n",
    "\t\t\t\t\t\t\t confusion_matrix, ConfusionMatrixDisplay, \n",
    "\t\t\t\t\t\t\t accuracy_score, recall_score, precision_score, f1_score,\n",
    "\t\t\t\t\t\t\t log_loss, hinge_loss, mean_absolute_error, mean_squared_error, r2_score)\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score, AUROC, ConfusionMatrix, MeanSquaredError, MeanAbsoluteError, R2Score, MetricCollection\n",
    "import statsmodels.api as sm \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly average electricity consumption + temperture\n",
    "\n",
    "avg_t_mean = df.groupby('Month')['Avg Temperature (Celsius)'].mean()\n",
    "avg_pc_mean = df.groupby('Month')['Avg Electricity Consumption per Household (kWh)'].mean()\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "fig.set_facecolor('white') \n",
    "ax = fig.add_subplot()\n",
    " \n",
    "ax.bar(avg_t_mean.index, avg_t_mean , label='Avg Temperature (Celsius)')\n",
    "ax.set_ylabel('Avg Temperature (Celsius)', fontsize=14, color='black') \n",
    "ax.set_xlabel('Month', fontsize=14, color='black')\n",
    " \n",
    "ax2 = ax.twinx()\n",
    "ax2.set_ylabel('Avg Electricity Consumption per Household (kWh)', fontsize=14, color='red')\n",
    "ax2.plot(avg_pc_mean.index ,avg_pc_mean, label='Avg Electricity Consumption per Household (kWh)',color='red', linewidth = 5)\n",
    "\n",
    "plt.xticks(np.arange(0,13,1),rotation=0)\n",
    "plt.title('Avg Temperature & Avg Electricity Consumption per Household (kWh)',fontsize=20)\n",
    "plt.legend(loc = 2, fontsize=20, frameon=True, shadow=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #Year per: 84 Month per: 70 Region per: 140 Total data:840\n",
    "# \n",
    "# monthly_data = df.groupby('Region')['Avg Electricity Consumption per Household (kWh) Household (kWh)'].mean( ).reset_index()\n",
    "# df_mean=df.groupby(['YeaAvg Electricity Consumption per Household (kWh)r Househol# d (kWh)']).mean()\n",
    "# unstacked_df = df_mean.unst# ack(level='Year')\n",
    "# fig, ax_1 = plt.subplot# s(figsize=(12, 8))\n",
    "# ax_1.set# _xlabel('Region')\n",
    "# ax_1.set_xticks# (monthly_data.indAvg Electricity Consumption per Household (kWh)on # per Household (kWh)')\n",
    "# ax_1.plot(monthly_data['LocAvg Electricity Consumption per Household (kWh)'on per Household (kWh)'], color='orange',mark# er='o', ms=4,alpha=1)\n",
    "\n",
    "# ax_1.tick_params(axis='# y', labelcolor='orange')\n",
    "# ### #####\n",
    "# ax_2 = ax_Small Pan Evaporation (mm)('S# mall Pan Evaporation (mm)')\n",
    "# unstacked_df.plot(k# ind='bar',ax=ax_2,alpha=0.5)\n",
    "# ax_2.tick_params(# axis='y', labelcolor='blue')\n",
    "\n",
    "# plt.title(f'Avg Electricity Consumption per Household#  (kWh) from#  Region,Region'# )\n",
    "# plt.grid()\n",
    "# plt.tight_layout()\n",
    "# for x_val,y_val in zip(monthly_data['Region'],monthly_data['Avg Electricity C# onsumption per Household (kWh)']):\n",
    "# \tax_1.text(x_val, y_val +0.1,f'{y_val:.2f}',ha='center',va='bottom'# ,fontsize=9,color='black',zorde# r=5)\n",
    "# plt.subplots_adjust(right=1.8)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(models: List[Union[GridSearchCV, BaseEstimator]], X_train_list: List[pd.DataFrame], X_test_list: List[pd.DataFrame], y_train: pd.Series, y_test: pd.Series) -> pd.DataFrame:\n",
    "\t\"\"\"\n",
    "\tEvaluates a list of models (either GridSearchCV objects or regular estimators)\n",
    "\ton training and test data, and returns a summary DataFrame of evaluation metrics.\n",
    "\n",
    "\tParameters:\n",
    "\t\tmodels (List[Union[GridSearchCV, BaseEstimator]]): List of models to evaluate.\n",
    "\t\tX_train_list (List[pd.DataFrame]): Training features.\n",
    "\t\tX_test_list (List[pd.DataFrame]): Testing features.\n",
    "\t\ty_train (pd.Series): Training labels.\n",
    "\t\ty_test (pd.Series): Testing labels.\n",
    "\n",
    "\tReturns:\n",
    "\t\tpd.DataFrame: A summary table with model name, evaluation metrics,\n",
    "\t\t\t\t\t  training time, and best hyperparameters (if available).\n",
    "\t\"\"\"\n",
    "\tresults = []\n",
    "\t\n",
    "\tfor i, (X_train, X_test) in enumerate(zip(X_train_list, X_test_list)):\n",
    "\t\tfor model in models:\n",
    "\t\t\t# Training for each X_train\n",
    "\t\t\tmodel_clone = clone(model)\n",
    "\t\t\tmodel_clone.fit(X_train, y_train)\n",
    "\t\t\t\n",
    "\t\t\t# Check if a model is a GridSearchCV object\n",
    "\t\t\tif isinstance(model_clone, GridSearchCV):\n",
    "\t\t\t\tbest_model = model_clone.best_estimator_\n",
    "\t\t\t\tbest_hyperparams = model_clone.best_params_\n",
    "\t\t\telse:\n",
    "\t\t\t\tbest_model = model\n",
    "\t\t\t\tbest_hyperparams = 'N/A'\n",
    "\t\t\tmodel_name = str(best_model.__class__.__name__)\n",
    "\t\t\t\n",
    "\t\t\t# Testing for each X_test\n",
    "\t\t\ty_pred = best_model.predict(X_test)\n",
    "\t\t\t\n",
    "\t\t\t# Evaluation\n",
    "\t\t\tmae = mean_absolute_error(y_test,y_pred)\n",
    "\t\t\tmse = mean_squared_error(y_test, y_pred)\n",
    "\t\t\trmse = np.sqrt(mse)\n",
    "\t\t\tr2 = r2_score(y_test,y_pred)\n",
    "\t\t\tadj_r2 = adj_r2_score(y_test,y_pred,X_test)\n",
    "\t\t\t\n",
    "\t\t\t# Result dataframe\n",
    "\t\t\tresult = pd.DataFrame({'Feature Index': [i],\n",
    "\t\t\t\t\t\t\t\t   'Model': [model_name],\n",
    "\t\t\t\t\t\t\t\t   'MAE': [mae],\n",
    "\t\t\t\t\t\t\t\t   'RMSE': [rmse],\n",
    "\t\t\t\t\t\t\t\t   'R^2': [r2],\n",
    "\t\t\t\t\t\t\t\t   'Adj-R^2': [adj_r2],\n",
    "\t\t\t\t\t\t\t\t   'Training time': [training_time],\n",
    "\t\t\t\t\t\t\t\t   'Best hyperparameters': [best_hyperparams]})\n",
    "\t\t\tresults.append(result)\n",
    "\t\t\t\n",
    "\t\t# Sort results by Model\n",
    "\t\tresults = pd.concat(results).sort_values(by=['Feature Index', 'Model']).reset_index(drop=True)\n",
    "\n",
    "\treturn results\n",
    "\n",
    "models = [model_lr, model_en, model_dt, model_svr, model_rf, model_ada, model_xgb, model_stacking]\n",
    "results = evaluation(models=models, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trains=[X1_train,X2_train,X3_train,X4_train,X5_train]\n",
    "X_tests=[X1_test,X2_test,X3_test,X4_test,X5_test]\n",
    "dummy_prefix = 'Location'\n",
    "dummy_sep = '_'\n",
    "for i, (train_df, test_df) in enumerate(zip(X_trains, X_tests)):\n",
    "    print(f\"  처리 중: {i+1}번째 Train/Test 쌍\") # i+1 하면 1, 2, 3, 4, 5 가 됩니다.\n",
    "    train_name=f'X{i+1}_train'\n",
    "    test_name=f'X{i+1}_test'\n",
    "    train_processed = pd.get_dummies(train_df, columns=['Location'],dtype=int, prefix=dummy_prefix, prefix_sep=dummy_sep)\n",
    "    test_processed = pd.get_dummies(test_df, columns=['Location'],dtype=int, prefix=dummy_prefix, prefix_sep=dummy_sep)\n",
    "    all_cols = list(set(train_processed.columns) | set(test_processed.columns))\n",
    "    train_reindexed = train_processed.reindex(columns=all_cols, fill_value=0)\n",
    "    test_reindexed = test_processed.reindex(columns=all_cols, fill_value=0)\n",
    "    # 원-핫 인코딩 시 사용한 prefix를 기준으로 더미 컬럼 식별\n",
    "    dummy_cols = [col for col in train_reindexed.columns if col.startswith(f\"{dummy_prefix}{dummy_sep}\")]\n",
    "    # 더미 컬럼을 제외한 나머지를 스케일링 대상 숫자형 컬럼으로 간주\n",
    "    numerical_cols = [col for col in train_reindexed.columns if col not in dummy_cols]\n",
    "    scaler=StandardScaler()\n",
    "    scaler.fit(train_reindexed[numerical_cols])\n",
    "    scaled_train_numerical_np = scaler.transform(train_reindexed[numerical_cols])\n",
    "    train_scaled_numerical_df = pd.DataFrame(scaled_train_numerical_np,\n",
    "                                             index=train_reindexed.index,\n",
    "                                             columns=numerical_cols)\n",
    "\n",
    "    scaled_test_numerical_np = scaler.transform(test_reindexed[numerical_cols])\n",
    "    test_scaled_numerical_df = pd.DataFrame(scaled_test_numerical_np,\n",
    "                                            index=test_reindexed.index,\n",
    "                                            columns=numerical_cols)\n",
    "    final_train_df = pd.concat([train_scaled_numerical_df, train_reindexed[dummy_cols]], axis=1)\n",
    "    final_test_df = pd.concat([test_scaled_numerical_df, test_reindexed[dummy_cols]], axis=1)\n",
    "\n",
    "    print(f\"    스케일링 대상 컬럼 (Numerical): {numerical_cols}\")\n",
    "    print(f\"    유지 대상 컬럼 (Dummy): {dummy_cols}\")\n",
    "    globals()[train_name] = final_train_df\n",
    "    globals()[test_name] = final_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise_selection(X, y,\n",
    "\t\t\t\t\t   initial_list=[],\n",
    "\t\t\t\t\t   threshold_in=0.05,\n",
    "\t\t\t\t\t   threshold_out=0.10,\n",
    "\t\t\t\t\t   verbose=True):\n",
    "\t\"\"\"\n",
    "\tPerform a stepwise feature selection based on p-values from statsmodels OLS.\n",
    "\n",
    "\tParameters:\n",
    "\t- X : pd.DataFrame\n",
    "\t\tCandidate feature set (independent variables).\n",
    "\t- y : pd.Series or np.array\n",
    "\t\tTarget variable (dependent variable).\n",
    "\t- initial_list : list\n",
    "\t\tInitial list of features to start the selection process.\n",
    "\t- threshold_in : float\n",
    "\t\tp-value threshold for adding a feature (smaller = more strict).\n",
    "\t- threshold_out : float\n",
    "\t\tp-value threshold for removing a feature (larger = more lenient).\n",
    "\t- verbose : bool\n",
    "\t\tWhether to print progress during feature selection.\n",
    "\n",
    "\tReturns:\n",
    "\t- included : list\n",
    "\t\tThe final list of selected features.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tincluded = list(initial_list)  # Start with an initial list (could be empty)\n",
    "\t\n",
    "\twhile True:\n",
    "\t\tchanged = False  # Flag to track whether any feature was added or removed in the current iteration; If not, the loop will break\n",
    "\n",
    "\t\t# --- Forward Step ---\n",
    "\t\t# Try adding each feature not yet included and check p-values\n",
    "\t\texcluded = list(set(X.columns) - set(included))  # Compute the list of features not yet included in the model; These are the candidates for addition\n",
    "\t\tnew_pval = pd.Series(index=excluded, dtype=float)  # Initialise a Series to store the p-values of each excluded feature if it were to be added to the model\n",
    "\t\tfor new_column in excluded: # Iterate over all excluded features to assess their contribution\n",
    "\t\t\t# Fit OLS model with the current included features + this new one\n",
    "\t\t\tX_with_const = sm.add_constant(X[included + [new_column]]) # Prepare the design matrix with a constant term (intercept) and the current included features plus the candidate new feature\n",
    "\t\t\tmodel = sm.OLS(y, X_with_const).fit() # Fits an Ordinary Least Squares (OLS) linear regression model to the current design matrix\n",
    "\t\t\tnew_pval[new_column] = model.pvalues[new_column]  # Extract the p-value of the newly added feature and stores it\n",
    "\n",
    "\t\t# Add the feature with the lowest p-value if it's below threshold_in\n",
    "\t\tif not new_pval.empty and new_pval.min() < threshold_in: # Check whether the smallest p-value among the excluded features is statistically significant, i.e., below the inclusion threshold\n",
    "\t\t\tbest_pval = new_pval.idxmin()  # Feature with the smallest p-value\n",
    "\t\t\tincluded.append(best_pval)\n",
    "\t\t\tchanged = True\n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tprint(f'Add {best_pval} with p-value {new_pval.min():.6f}')\n",
    "\n",
    "\t\t# --- Backward Step ---\n",
    "\t\t# Now check if any included feature should be removed\n",
    "\t\tX_with_const = sm.add_constant(X[included]) \n",
    "\t\tmodel = sm.OLS(y, X_with_const).fit() # Re-fit the model using the current set of included features to re-calculate all p-values\n",
    "\t\tpvalues = model.pvalues.iloc[1:]  # Get p-values for all features excluding the intercept (which is the first value); These are the features being evaluated for possible removal\n",
    "\n",
    "\t\t# If any included feature has a p-value above threshold_out, remove the worst one\n",
    "\t\tif not pvalues.empty and pvalues.max() > threshold_out: # If the worst (largest) p-value among included features exceeds the exclusion threshold, it’s a candidate for removal\n",
    "\t\t\tworst_pval = pvalues.idxmax() # Find the feature with the worst (largest) p-value\n",
    "\t\t\tincluded.remove(worst_pval) # Remove this feature from the model\n",
    "\t\t\tchanged = True\n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tprint(f'Drop {worst_pval} with p-value {pvalues.max():.6f}')\n",
    "\n",
    "\t\t# If no feature was added or removed, the process is done\n",
    "\t\tif not changed:\n",
    "\t\t\tbreak\n",
    "\n",
    "\t# Print final selected features and summary\n",
    "\tif verbose:\n",
    "\t\tprint(\"\\nFinal Selected Variables:\")\n",
    "\t\tprint(included)\n",
    "\t\tfinal_X_with_const = sm.add_constant(X[included])\n",
    "\t\tfinal_model = sm.OLS(y, final_X_with_const).fit()\n",
    "\t\tprint(\"\\nFinal Model Summary:\")\n",
    "\t\tprint(final_model.summary())\n",
    "\n",
    "\treturn included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weak_corr_col(X: pd.DataFrame, Y: pd.Series, feature: str, threshold: float):\n",
    "\t\"\"\"\n",
    "\tIdentify numeric columns that are weakly correlated with a specified feature.\n",
    "\n",
    "\tParameters:\n",
    "\t- X (pd.DataFrame): Feature dataset.\n",
    "\t- Y (pd.Series): Target variable to be appended for correlation analysis.\n",
    "\t- feature (str): The column name to compare correlations against.\n",
    "\t- threshold (float): Absolute correlation threshold; columns with correlation\n",
    "\t\t\t\t\t\t less than this value will be returned.\n",
    "\n",
    "\tReturns:\n",
    "\t- pd.Index: Column names with absolute correlation to the specified feature\n",
    "\t\t\t\tless than the given threshold.\n",
    "\t\"\"\"\n",
    "\tdf = pd.concat([X, Y], axis=1)\n",
    "\tdf_numeric = df.select_dtypes(include=['number'])\n",
    "\tdf_corr = df_numeric.corr()\n",
    "\tweak_corr_cols = df_corr[abs(df_corr[feature]) < threshold].index\n",
    "\t\n",
    "\treturn weak_corr_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_r2_score(y_true: pd.Series, y_pred: pd.Series, X_features: pd.DataFrame) -> float:\n",
    "\t\"\"\"\n",
    "\tCompute the adjusted R² (coefficient of determination).\n",
    "\n",
    "\tAdjusted R² adjusts the regular R² score for the number of predictors (features)\n",
    "\tin the model. It penalizes the R² score for adding unnecessary predictors, helping\n",
    "\tto avoid overfitting.\n",
    "\n",
    "\tParameters:\n",
    "\t- y_true : array-like of shape (n_samples,)\n",
    "\t\tTrue target values.\n",
    "\t- y_pred : array-like of shape (n_samples,)\n",
    "\t\tPredicted target values from the model.\n",
    "\t- X_features : array-like of shape (n_samples, n_features)\n",
    "\t\tData used for getting the number of predictors (features) used in the model.\n",
    "\n",
    "\tReturns:\n",
    "\t- adj_r2 : float\n",
    "\t\tThe adjusted R-squared score. Returns NaN if the number of predictors is too large\n",
    "\t\tfor the formula to be valid (i.e., n <= p + 1).\n",
    "\t\"\"\"\n",
    "\tn = len(y_true)\n",
    "\tp = X_features.shape[1]\n",
    "\t\n",
    "\t# Prevent division by zero or negative denominator\n",
    "\tif n <= p + 1:\n",
    "\t\twarnings.warn(\"Adjust R^2 is undefined.\")\n",
    "\t\treturn float('nan')\n",
    "\t\n",
    "\treturn 1 - (1 - r2_score(y_true, y_pred)) * (n - 1) / (n - p - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model: BaseEstimator,  \n",
    "\t\t\t\t   X_test: pd.DataFrame, \n",
    "\t\t\t\t   y_test: pd.Series) -> Tuple[pd.Series, float, float, float, float]:\n",
    "\t\"\"\"\n",
    "\tTrain a regression model and evaluates its performance on the test set.\n",
    "\n",
    "\tParameters:\n",
    "\t\tmodel (BaseEstimator): The regression model to train (already instantiated, e.g., from GridSearchCV.best_estimator_).\n",
    "\t\tX_test (pd.DataFrame): Testing features.\n",
    "\t\ty_test (pd.Series): Testing target values.\n",
    "\n",
    "\tReturns:\n",
    "\t\tTuple containing:\n",
    "\t\t\t- y_pred (pd.Series): Predicted target values on the test set.\n",
    "\t\t\t- mae (float): Mean Absolute Error.\n",
    "\t\t\t- rmse (float): Root Mean Squared Error.\n",
    "\t\t\t- r2 (float): R-squared score.\n",
    "\t\t\t- adj_r2 (float): Adjusted R-squared score.\n",
    "\t\"\"\"\n",
    "\ty_pred = model.predict(X_test)\n",
    "\tmae = mean_absolute_error(y_true=y_test, y_pred=y_pred)\n",
    "\tmse = mean_squared_error(y_true=y_test, y_pred=y_pred)\n",
    "\trmse = math.sqrt(mse)\n",
    "\tr2 = r2_score(y_true=y_test, y_pred=y_pred)\n",
    "\tadj_r2 = adj_r2_score(y_true=y_test, y_pred=y_pred, X_features=X_test)\n",
    "\t\n",
    "\treturn y_pred, mae, rmse, r2, adj_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../data/cleaned/energy_consumption.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split for features and target\n",
    "X = df.drop(columns=['Avg Electricity Consumption per Household (kWh)', 'Avg Gas Supply per Household (ton)'])\n",
    "y = df['Avg Electricity Consumption per Household (kWh)']\n",
    "# y = df['Avg Gas Supply per Household (ton)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab column names of each data type\n",
    "numerical_cols = X.select_dtypes(include=['number']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "datetime_cols = X.select_dtypes(include=['datetime']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split for train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region one hot encoding\n",
    "X_train = pd.get_dummies(data=X_train, columns=['Region'], dtype=int)\n",
    "X_test = pd.get_dummies(data=X_test, columns=['Region'], dtype=int)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X0 - All\n",
    "X0_train = X_train.copy()\n",
    "X0_test = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1 - Correlation\n",
    "weak_corr_cols = weak_corr_col(X_train, y_train,'Avg Electricity Consumption per Household (kWh)', 0.2)\n",
    "X1_train = X_train.drop(columns=(weak_corr_cols))   \n",
    "X1_test = X_test.drop(columns=(weak_corr_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config setting\n",
    "# Elastic net\n",
    "model_en = ElasticNet(random_state=42)\n",
    "hyperparams_en = {'alpha': [0.1, 1, 10],\n",
    "\t\t\t\t  'l1_ratio': [0.1, 0.5, 0.9]}                          \n",
    "config_en = [model_en, hyperparams_en]\n",
    "\n",
    "# SVR\n",
    "model_svr = SVR()\n",
    "hyperparams_svr = {'kernel': ['poly', 'rbf', 'sigmoid'],\n",
    "\t\t\t\t   'C':[10, 100, 1000],\n",
    "\t\t\t\t   'epsilon':[0.3,0.5,0.8]}\n",
    "config_svr = [model_svr, hyperparams_svr]\n",
    "\n",
    "# XGB\n",
    "model_xgb = XGBRegressor(random_state=42)\n",
    "hyperparams_xgb = {'n_estimators': [100, 200, 300],\n",
    "\t\t\t\t   'learning_rate': [0.01, 0.05, 0.1],\n",
    "\t\t\t\t   'max_depth': [3, 5, 7]}\n",
    "config_xgb = [model_xgb, hyperparams_xgb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combinations(models_dict: Dict[str, Any], max_k:int, min_k: int) -> List[Tuple[Tuple[str, Any], ...]]:\n",
    "\t\"\"\"\n",
    "    Generate all possible combinations of base learners from a dictionary of models,\n",
    "    with combination sizes ranging from min_k to max_k.\n",
    "\n",
    "    Parameters:\n",
    "    models_dict : dict\n",
    "        A dictionary where keys are model names and values are trained model objects.\n",
    "        Example: {'ElasticNet': model_1, 'XGBRegressor': model_2}\n",
    "\n",
    "    min_k : int, optional (default=2)\n",
    "        The minimum number of base models in a combination.\n",
    "\n",
    "    max_k : int, optional (default=6)\n",
    "        The maximum number of base models in a combination.\n",
    "\n",
    "    Returns:\n",
    "    all_combos : list of tuples\n",
    "        Each tuple contains a combination of (model_name, model_object) pairs.\n",
    "        Example: [(('ElasticNet', model1), ('XGBRegressor', model2)), ...]\n",
    "    \"\"\"\n",
    "\t# Convert the dictionary into a list of (key, value) tuples\n",
    "\titems = list(models_dict.items())\n",
    "\t\n",
    "\t# Initialisation\n",
    "\tcombinations = []\n",
    "\t\n",
    "\t# Ensure max_k does not exceed the number of available models\n",
    "\tmax_k = min(max_k, len(items))\n",
    "\t\n",
    "\t# Generate combinations of size k from min_k to max_k\n",
    "\tfor k in range(min_k, max_k + 1):\n",
    "\t\tcombos = itertools.combinations(items, k)\n",
    "\t\tfor combo in combos:\n",
    "\t\t\tcombinations.append(combo)\n",
    "\t\t\t\n",
    "\treturn combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models and X to test\n",
    "models = [config_linear_regression, config_en, config_svr, config_dt, config_rf, config_ada, config_xgb]\n",
    "X_trains=[X0_train, X1_train, X2_train, X3_train, X4_train]\n",
    "X_tests=[X0_test, X1_test, X2_test, X3_test, X4_test]\n",
    "\n",
    "# Initialisation\n",
    "best_estimators_dict = {}\n",
    "best_params_dict = {}\n",
    "modelling_results = []\n",
    "stacking_results = []\n",
    "feature_importances = []\n",
    "\n",
    "# Iterate over each feature (X0, X1, ...)\n",
    "for data_idx, (X_train, X_test) in enumerate(zip(X_trains, X_tests)):\n",
    "\tdata_tag = f'X{data_idx}' # Label for current dataset\n",
    "\tprint(f\"Running on {data_tag}\")\n",
    "\t\n",
    "\tbest_estimators_dict[data_tag] = {}\n",
    "\tbest_params_dict[data_tag] = {}\n",
    "\t\n",
    "\t# Iterate over all models\n",
    "\tfor model_idx, (estimator, param_grid) in enumerate(models):\n",
    "\t\tmodel_name = estimator.__class__.__name__\n",
    "\t\t\n",
    "\t\t# Training\n",
    "\t\tgrid_search = GridSearchCV(estimator=estimator,\n",
    "\t\t\t\t    \t\t\t   param_grid=param_grid,\n",
    "\t\t\t\t\t\t\t\t   cv=5)\n",
    "\t\tstart_time = time.time()\n",
    "\t\tgrid_search.fit(X_train, y_train)\n",
    "\t\tend_time = time.time()\n",
    "\t\ttraining_time = end_time - start_time\n",
    "\t\t\n",
    "\t\t# Store the best model and its hyperparameters\n",
    "\t\tbest_model = grid_search.best_estimator_\n",
    "\t\tbest_params = grid_search.best_params_\n",
    "\t\tbest_estimators_dict[data_tag][model_name] = best_model\n",
    "\t\tbest_params_dict[data_tag][model_name] = best_params\n",
    "\t\t\n",
    "\t\t# Testing and evaluating\n",
    "\t\ty_pred, mae, rmse, r2, adj_r2 = evaluate_model(best_model, X_test, y_test)\n",
    "\t\t\n",
    "\t\t# Log result\n",
    "\t\tmodelling_results.append({'y_test':y_test,\n",
    "\t\t\t\t\t\t\t\t  'y_pred':y_pred,\n",
    "\t\t\t\t\t\t\t\t  'Data': data_tag,\n",
    "\t\t\t\t\t\t\t\t  'Model': model_name,\n",
    "\t\t\t\t\t\t\t\t  'Training time': training_time,\n",
    "\t\t\t\t\t\t\t\t  'Best hyperparams': best_params,\n",
    "\t\t\t\t\t\t\t\t  'MAE': mae,\n",
    "\t\t\t\t\t\t\t\t  'RMSE': rmse,\n",
    "\t\t\t\t\t\t\t\t  'R^2': r2,\n",
    "\t\t\t\t\t\t\t\t  'Adjusted R^2': adj_r2})\n",
    "\t\n",
    "\t# Stacking\n",
    "\testimators = best_estimators_dict[data_tag]\n",
    "\t\n",
    "\t# Rank models by adjusted R^2\n",
    "\tdf_results = (pd.DataFrame([result for result in modelling_results if result['Data']==data_tag])\n",
    "\t\t\t\t  .sort_values(by='Adjusted R^2', ascending=False)\n",
    "\t\t\t\t  .reset_index(drop=True))\n",
    "\t\n",
    "\t# Select the meta learner w/ top performances\n",
    "\tmeta_learner_name = df_results.iloc[0]['Model']\n",
    "\tmeta_model = estimators[meta_learner_name]\n",
    "\t\n",
    "\t# Select next best models as base learners\n",
    "\tbase_candidates = df_results.iloc[1:]['Model'].tolist()\n",
    "\tbase_objects = {name: estimators[name] for name in base_candidates}\n",
    "\t\n",
    "\tbest_adj_r2 = 0\n",
    "\tbest_combo = None\n",
    "\tbest_stacking = None\n",
    "\t\n",
    "\t# print(f\"[{data_tag}] Meta Learner: {meta_learner_name}\")\n",
    "\t# print(f\"[{data_tag}] Base candidates: {list(base_objects.keys())}\")\n",
    "\t\n",
    "\t# Try all combinations of base learners\n",
    "\tfor combo in generate_combinations(base_objects, max_k=6, min_k=1):\n",
    "\t\t# print(f\"[{data_tag}] Trying combo: {combo}\")\n",
    "\t\tcombo_names, estimators_combo = zip(*combo)\n",
    "\t\t\n",
    "\t\t# Build the stacking model\n",
    "\t\tstack_model = StackingRegressor(estimators=list(zip(combo_names, estimators_combo)),\n",
    "\t\t\t\t\t\t\t\t\t\tfinal_estimator=meta_model,\n",
    "\t\t\t\t\t\t\t\t\t\tcv=5,\n",
    "\t\t\t\t\t\t\t\t\t\tn_jobs=-1)\n",
    "\t\t\n",
    "\t\ttry:\n",
    "\t\t\t# Training and testing\n",
    "\t\t\tstack_model.fit(X_train, y_train)\n",
    "\t\t\ty_pred, mae, rmse, r2, adj_r2 = evaluate_model(stack_model, X_test, y_test)\n",
    "\t\t\t\n",
    "\t\t\t# Update adjusted R^2 score\n",
    "\t\t\tif adj_r2 > best_adj_r2:\n",
    "\t\t\t\tbest_adj_r2 = adj_r2\n",
    "\t\t\t\tbest_combo = combo_names\n",
    "\t\t\t\tbest_stacking = stack_model\n",
    "\t\t\t\t# print(f\">>> New best adjusted R^2: {best_adj_r2}\")\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"Error during stacking with combination {combo_names}: {e}\")\n",
    "\t\n",
    "\t# Log the best stacking model if one was found\n",
    "\tif best_stacking:\n",
    "\t\ty_pred, mae, rmse, r2, adj_r2 = evaluate_model(best_stacking, X_test, y_test)\n",
    "\t\t\n",
    "\t\tstacking_results.append({'y_test':y_test,\n",
    "\t\t\t\t\t\t   \t\t 'y_pred':y_pred,\n",
    "\t\t\t\t\t\t\t\t 'Data': data_tag,\n",
    "\t\t\t\t\t\t\t\t 'Model': 'Stacking',\n",
    "\t\t\t\t\t\t\t\t 'Training time': 'N/A',\n",
    "\t\t\t\t\t\t\t\t 'Best hyperparams': {'Meta': meta_learner_name, 'Base': list(best_combo)},\n",
    "\t\t\t\t\t\t\t\t 'MAE': mae,\n",
    "\t\t\t\t\t\t\t\t 'RMSE': rmse,\n",
    "\t\t\t\t\t\t\t\t 'R^2': r2,\n",
    "\t\t\t\t\t\t\t\t 'Adjusted R^2': adj_r2})\n",
    "\t\t\n",
    "\t\t# Compute permutation importance\n",
    "\t\tresult = permutation_importance(best_stacking,\n",
    "\t\t\t\t\t\t\t\t\t\tX_test, \n",
    "\t\t\t\t\t\t\t\t\t\ty_test, \n",
    "\t\t\t\t\t\t\t\t\t\tn_repeats=10, \n",
    "\t\t\t\t\t\t\t\t\t\trandom_state=42, \n",
    "\t\t\t\t\t\t\t\t\t\tn_jobs=-1, \n",
    "\t\t\t\t\t\t\t\t\t\tscoring='r2')\n",
    "\t\t\n",
    "\t\tfeature_names = X_test.columns if isinstance(X_test, pd.DataFrame) else [f'Feature {i}' for i in range(X_test.shape[1])]\n",
    "\t\t\n",
    "\t\tdf_perm = (pd.DataFrame({'Data': data_tag,\n",
    "\t\t\t\t\t\t\t\t 'Feature': feature_names,\n",
    "\t\t\t\t\t\t\t\t 'Mean importance': result.importances_mean,\n",
    "\t\t\t\t\t\t\t\t 'Std importance': result.importances_std})\n",
    "\t\t\t\t   .sort_values(by='Mean importance', ascending=False)\n",
    "\t\t\t\t   .reset_index(drop=True))\n",
    "\t\t\n",
    "\t\tfeature_importances.append(df_perm)\n",
    "\n",
    "# Final DataFrame\t\t\t\n",
    "df_modelling = pd.DataFrame(modelling_results)\n",
    "df_stacking = pd.DataFrame(stacking_results)\n",
    "df_models = pd.concat([df_modelling, df_stacking])\n",
    "df_feature_importance = pd.concat(feature_importances, ignore_index=True)\n",
    "\n",
    "# print(\"\\n Model performance summary:\")\n",
    "# print(df_modelling)\n",
    "\n",
    "# print(\"\\n Stacking performance summary:\")\n",
    "# print(df_stacking)\n",
    "\n",
    "# print(\"\\n Feature importance from stacking models:\")\n",
    "# print(df_feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearch 모델에 들어갈\n",
    "models = [config_linear_regression, config_en, config_svr, config_dt, config_rf, config_ada, config_xgb]\n",
    "# models = [config_en, config_svr, config_dt, config_ada, config_xgb]\n",
    "num=0\n",
    "n=0\n",
    "#X_trains,X_tests는 Feature Selection 그룹\n",
    "X_trains=[X0_train, X1_train, X2_train, X3_train, X4_train]\n",
    "X_tests=[X0_test, X1_test, X2_test, X3_test, X4_test]\n",
    "\n",
    "\n",
    "for X_train, X_test in zip(X_trains,X_tests):\n",
    "    #DF에 들어갈 특성그룹 번호\n",
    "    Data_num='X'+str(num+1)\n",
    "    #현재 돌아가고 있는 위치\n",
    "    print(num)\n",
    "    for i in range(len(models)):\n",
    "        #현재 돌아가고있는 위치 2\n",
    "        print(n)\n",
    "        #Model-> 모델 선언 ex)SVR(),XGBRegressor()\n",
    "        Model=models[i][0]\n",
    "        #Hyperparams-> Hyperparam의 튜닝 모음\n",
    "        Hyperparams=models[i][1]\n",
    "\n",
    "        #Model,Hyperparams를 통해 GridSearch 하이퍼파라미터 설정\n",
    "        model_info = GridSearchCV(estimator=Model,\n",
    "                            param_grid = Hyperparams,\n",
    "                            cv=5)\n",
    "        start_time = time.time()\n",
    "        #GridSearch 훈련\n",
    "        model_info.fit(X_train,y_train)\n",
    "        end_time = time.time()\n",
    "        #model_n:각 모델의 좋은 성능을 가진 모델\n",
    "        #ex)XGBRegressor(n_estimators:300,learning_rate:0.1,max_depth:5)\n",
    "        #위 모델이 성능이 좋을 때 model_n은 저 모델를 가져옴\n",
    "        model_n = model_info.best_estimator_\n",
    "\n",
    "        #para:model_n에서 하이퍼파라미터만 출력\n",
    "        #model_n에서 예시를 들면 전체가 아니라 뒤에 ()내용만 출력\n",
    "        para=model_info.best_params_\n",
    "\n",
    "        #model_n은 위에서 언급했듯이 모델(하이퍼파라미터)출력\n",
    "        #이것을 문자열로 변환\n",
    "        model_name = str(model_n)\n",
    "\n",
    "        #모델 이름은 (앞에 있으므로 (로 스플릿 이후 0번째 인덱스\n",
    "        model_name = model_name.split('(')[0]\n",
    "\n",
    "       \n",
    "        model_n.fit(X_train,y_train)\n",
    "       \n",
    "\n",
    "        y_pred= model_n.predict(X_test)\n",
    "\n",
    "         #MAE,RMSE,R2,Adj-R2\n",
    "        mae=mean_absolute_error(y_test,y_pred)\n",
    "\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        R2 = r2_score(y_test,y_pred)\n",
    "        adj_r2 = adj_r2_score(y_test,y_pred,X_test)\n",
    "\n",
    "        #model Df  중간 오류 발생위험으로 y_test,y_pred를 제외하고 하나씩 추가\n",
    "        model = pd.DataFrame({'y_test':y_test,'y_pred':y_pred})\n",
    "        model['MAE'] = mae\n",
    "        model['RMSE'] = rmse\n",
    "        model['R^2'] = R2\n",
    "        model['adj-R^2'] =adj_r2\n",
    "        model['Model'] = model_name\n",
    "        model['Training_time'] = end_time - start_time\n",
    "        model['Data_number']=Data_num\n",
    "        params=[]\n",
    "        #para는 딕션너리 형태로 되어있음\n",
    "        for param, value in para.items():\n",
    "            #딕션너리중 param은 변수,value 값\n",
    "            params.append([param, value])\n",
    "        new_column_name = 'best_params'\n",
    "\n",
    "        #params를 출력하고 model의 길이만큼 복사\n",
    "        list_to_assign = [params] * len(model)\n",
    "\n",
    "        #새로운 열로 추가\n",
    "        model[new_column_name] = list_to_assign\n",
    "        if n == 0 :\n",
    "            result_model = model\n",
    "            n += 1\n",
    "        else:\n",
    "            result_model = pd.concat([result_model, model])\n",
    "            n += 1\n",
    "\n",
    "\n",
    " ####Stacking Code\n",
    "        #변수를 global함수를 사용하여 선언\n",
    "        globals()[model_name] = model_n\n",
    "\n",
    "    condition = (result_model['Data_number']==Data_num) #X1~X5-> Data_num\n",
    "    result_models=result_model[condition] #위에 조건에 맞는 DF\n",
    "    #adj-R^2가 높은 순으로 정렬\n",
    "    result_models=result_models.sort_values(by=[\"y_test\",'adj-R^2'], ascending=[True,False])\n",
    "    # 가장 좋은 모델의 이름(문자열)->메타모델\n",
    "    meta_learner_name = result_models.iloc[0]['Model']\n",
    "    # 변수 초기화\n",
    "    final_meta_estimator = None\n",
    "    #위에서 선언한 함수의 이름으로 선언\n",
    "    meta_model_object = globals()[meta_learner_name]\n",
    "    final_meta_estimator = meta_model_object#RF면 meta_model_object=Rf_best_estimator_\n",
    "    print(\"Meta Learner for Stacking:\", final_meta_estimator) #meta 모델 출력\n",
    "    length=len(models)\n",
    "    base_learner_names_series=result_models.iloc[1:length]['Model']\n",
    "    base_learner_names = base_learner_names_series.tolist()\n",
    "    # 후보 Base Learner 객체 가져오기\n",
    "    potential_base_objects = {}\n",
    "    valid_potential_base_names = [] # 실제로 객체를 찾은 이름만 저장\n",
    "    for name in base_learner_names:\n",
    "        model_object = globals()[name]\n",
    "        actual_estimator = model_object#RF면 actual_estimator=Rf_best_estimator_\n",
    "        potential_base_objects[name] = actual_estimator\n",
    "        valid_potential_base_names.append(name)\n",
    "    #모든 조합 시도 및 최적조합\n",
    "    best_adj_R_2 = 0 #큰값 찾을땐 0 작은값 찾을땐 float('inf')\n",
    "    best_combination_names = None\n",
    "    results_log = []\n",
    "    min_base_learners = 2 #최소개수(1개로 할까요?)\n",
    "    max_base_learners = min(6, len(valid_potential_base_names)) #6개 또는 최소값\n",
    "    if final_meta_estimator and len(valid_potential_base_names) >= min_base_learners:\n",
    "        start_combination_time = time.time()\n",
    "        total_combinations_tried = 0\n",
    "\n",
    "        for k in range(min_base_learners, max_base_learners + 1):\n",
    "            print(f\"\\n--- Trying combinations of size {k} ---\")\n",
    "            # 현재 크기 k의 모든 이름 조합 생성\n",
    "            for current_combination_names_tuple in itertools.combinations(valid_potential_base_names, k):\n",
    "                total_combinations_tried += 1\n",
    "                current_combination_names = list(current_combination_names_tuple)\n",
    "\n",
    "                # 현재 조합으로 estimators 리스트 생성\n",
    "                current_estimators = [(name, potential_base_objects[name]) for name in current_combination_names]\n",
    "\n",
    "                try:\n",
    "                    # Stacking Regressor 정의 및 학습\n",
    "                    ladder = StackingRegressor(estimators=current_estimators,\n",
    "                                            final_estimator=final_meta_estimator,\n",
    "                                            cv=5, # CV는 내부적으로 사용됨\n",
    "                                            n_jobs=-1) # 병렬 처리 사용 가능\n",
    "\n",
    "                    ladder.fit(X_train, y_train) # 훈련\n",
    "\n",
    "                    # 예측 및 MAE 계산\n",
    "                    y_pred_stack = ladder.predict(X_test)\n",
    "                    current_adj_R_2 = adj_r2_score(y_test, y_pred_stack, X_test) #<-R^2/adj_R^2/RMSE/MSE로 변경가능(metrics 변경시) \n",
    "\n",
    "                    # 결과 로깅\n",
    "                    results_log.append({'combination': current_combination_names, 'adj_R^2': current_adj_R_2}) #metrics 변경시 수정 \n",
    "                    # print(f\"  Combination: {current_combination_names}, MAE: {current_mae:.4f}\") # 상세 로그\n",
    "\n",
    "                    # 최고 기록 업데이트\n",
    "                    if current_adj_R_2 > best_adj_R_2:#metrics 변경시 수정  #큰값 찾을땐 > 작은값 찾을땐 <\n",
    "                        best_adj_R_2 = current_adj_R_2#metrics 변경시 수정 \n",
    "                        best_combination_names = current_combination_names\n",
    "                        print(f\" 🎯 >>> New Best adj_R^2: {best_adj_R_2:.2f} with combination: {best_combination_names}\") #metrics 변경시 수정 \n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error during stacking with combination {current_combination_names}: {e}\")\n",
    "\n",
    "        end_combination_time = time.time()\n",
    "        print(f\"\\n--- Combination Search Finished ---\")\n",
    "        print(f\"Total combinations tried: {total_combinations_tried}\")\n",
    "        print(f\"Search Time: {end_combination_time - start_combination_time:.2f} seconds\")\n",
    "\n",
    "        if best_combination_names:\n",
    "            print(f\"Best adj_R^2 found: {best_adj_R_2:.2f}\") #metrics 변경시 수정 \n",
    "            print(f\"Best Base Learner Combination: {best_combination_names}\")\n",
    "\n",
    "            # 최적 조합으로 최종 모델 구성 (필요시)\n",
    "            final_best_estimators = [(name, potential_base_objects[name]) for name in best_combination_names]\n",
    "            # 이 final_best_estimators 를 사용하여 최종 예측 또는 저장 등을 수행\n",
    "    else:\n",
    "        print(\"Could not find a best combination (possibly due to errors or no combinations tested).\")\n",
    "\n",
    "    #최적의 조합을 이용하여 데이터 예측\n",
    "    meta_name=['Meta',meta_learner_name]\n",
    "    #base 모델 이름 리스트 초기화\n",
    "    base_name=[]\n",
    "\n",
    "    for i in final_best_estimators:\n",
    "        #i[1]-> 하이퍼파라미터\n",
    "        base= i[0]\n",
    "        base_name.append(base)\n",
    "\n",
    "    print(\"Base Learners for Stacking:\", base_name)\n",
    "    #위에서 출력한 final_best_estimator로 훈련\n",
    "    ladder = StackingRegressor(estimators=final_best_estimators,\n",
    "                        final_estimator=final_meta_estimator,\n",
    "                        cv=5)\n",
    "    ladder.fit(X_train, y_train)\n",
    "\n",
    "    #예측\n",
    "    y_pred= ladder.predict(X_test)\n",
    "\n",
    "    #피처 중요도 \n",
    "    result = permutation_importance(\n",
    "    ladder, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1, scoring='r2' # 예시: 회귀, R2 기준\n",
    "    )\n",
    "    perm_sorted_idx = result.importances_mean.argsort() # 중요도 평균 기준 오름차순 인덱스\n",
    "    feature_names = X_test.columns if isinstance(X_test, pd.DataFrame) else [f'Feature {i}' for i in range(X_test.shape[1])]\n",
    "    perm_importance_data = {\n",
    "        'Feature': feature_names,\n",
    "        'Mean_Importance': result.importances_mean,\n",
    "        'Std_Importance': result.importances_std,\n",
    "        'Data_number': Data_num\n",
    "        }\n",
    "    perm_importance_df = pd.DataFrame(perm_importance_data)\n",
    "    if num==0:\n",
    "        perm_importance_df_all = perm_importance_df\n",
    "    else:\n",
    "        perm_importance_df_all = pd.concat([perm_importance_df_all, perm_importance_df])\n",
    "    # 중요도 기준으로 내림차순 정렬\n",
    "    perm_importance_df = perm_importance_df.sort_values(\n",
    "        by='Mean_Importance', ascending=False\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    print(\"\\n--- Permutation Importance (Original Features) DataFrame ---\")\n",
    "    print(perm_importance_df)\n",
    "    #MAE,RMSE,R2,Adj-R2\n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    R2 = r2_score(y_test,y_pred)\n",
    "    adj_r2 = adj_r2_score(y_test,y_pred,X_test)\n",
    "\n",
    "    #Stacking Df 제작 및 중간 오류 발생위험으로 y_test,y_pred를 제외하고 하나씩 추가\n",
    "    stacking = pd.DataFrame({'y_test':y_test,'y_pred':y_pred})\n",
    "    stacking['MAE'] = mae\n",
    "    stacking['RMSE'] = rmse\n",
    "    stacking['R^2'] = R2\n",
    "    stacking['adj-R^2'] = adj_r2\n",
    "    stacking['Model'] = 'Stacking'\n",
    "    stacking['Training_time'] = 0\n",
    "    #Data_number -> X1~X5\n",
    "    stacking['Data_number']=Data_num\n",
    "    #meta_model_name,base_model_name\n",
    "    params=[meta_name,base_name]\n",
    "    print(params)\n",
    "\n",
    "    #params를 stacking 크기만큼 복사\n",
    "    list_to_base_name = [params] * len(stacking)\n",
    "    stacking['best_params'] = list_to_base_name\n",
    "\n",
    "    if num == 0:\n",
    "        result_stack = stacking\n",
    "    else:\n",
    "        result_stack = pd.concat([result_stack, stacking])\n",
    "\n",
    "    num+=1\n",
    "#Model_stack으로 stacking과 model concat\n",
    "Model_stack = pd.concat([result_model, result_stack])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
